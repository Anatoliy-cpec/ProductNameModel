#–Ø –ø–æ–ª—å–∑—É—é—Å—å uv –æ–Ω –±—ã—Å—Ç—Ä–µ–µ pip –≤ —Ä–∞–∑—ã –∏ —Ä–µ—à–∞–µ –ø—Ä–æ–±–ª–µ–º—ã —Å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏ (–ø–æ—á—Ç–∏ –≤—Å–µ–≥–¥–∞)
!pip install uv
!uv pip install "arize-phoenix[evals,llama-index]"

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –í–°–ï–• –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∏–∑ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
!uv pip install -r requirements.txt

#–ù—É–∂–Ω–æ —á—Ç–æ–±—ã –ø–æ–¥—Ç—è–Ω—É—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ –ø–æ—Å–ª–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∏–Ω–∞—á–µ –∫–æ–Ω—Ñ–∏–∫—Ç, –ø–æ –∫—Ä–∞–π–Ω–µ–π –º–µ—Ä–µ –Ω–∞ –º–æ–º–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω–∏—è
!uv pip install openinference-instrumentation-llama-index

### –ò–º–ø–æ—Ä—Ç—ã

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# üß† LlamaIndex (–º–æ–¥—É–ª–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.llms.huggingface import HuggingFaceLLM

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# üì¶ –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ Python
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
import json              # –†–∞–±–æ—Ç–∞ —Å JSON-—Ñ–∞–π–ª–∞–º–∏
import logging           # –õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
import os                # –†–∞–±–æ—Ç–∞ —Å —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–æ–π
import re

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ü§ó Hugging Face / Transformers / PEFT
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
from huggingface_hub import hf_hub_download, login
from peft import LoraConfig, PeftConfig, PeftModel

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# üß™ Google Colab / IPython
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
import IPython
from google.colab.output import eval_js

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# üî¢ –ù–∞—É—á–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
import nest_asyncio
import numpy as np
import torch

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# üß† LlamaIndex (core)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
import llama_index.core
from llama_index.core import (
    ServiceContext,
    Settings,
    SimpleDirectoryReader,
    StorageContext,
    VectorStoreIndex,
)
from llama_index.core.callbacks import CallbackManager
from llama_index.core.postprocessor import LongContextReorder
from llama_index.core.prompts import PromptTemplate
from llama_index.core.query_engine import RetrieverQueryEngine
from llama_index.core.response.notebook_utils import display_source_node
from llama_index.core.retrievers import QueryFusionRetriever
from llama_index.core.vector_stores import SimpleVectorStore


### –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏

#–ó–∞–¥–∞—é —Ñ–æ—Ä–º–∞—Ç –ø—Ä–æ–º–ø—Ç–∞ –ø–æ–¥ –º–æ–¥–µ–ª—å –∫–æ—Ç–æ—Ä—É—é –±—É–¥—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å IlyaGusev/saiga_llama3_8b

#–í–æ—Ç –∏—Å—Ö–æ–¥–Ω—ã–π –ø—Ä–∏–º–µ—Ä —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –º–æ–¥–µ–ª–∏:
#<|begin_of_text|><|start_header_id|>system<|end_header_id|>
#–¢—ã ‚Äî –°–∞–π–≥–∞, —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –¢—ã —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞–µ—à—å —Å –ª—é–¥—å–º–∏ –∏ –ø–æ–º–æ–≥–∞–µ—à—å –∏–º.<|eot_id|><|start_header_id|>user<|end_header_id|>
#–ö–∞–∫ –¥–µ–ª–∞?<|eot_id|><|start_header_id|>assistant<|end_header_id|>
#–û—Ç–ª–∏—á–Ω–æ, –∞ —É —Ç–µ–±—è?<|eot_id|><|start_header_id|>user<|end_header_id|>
#–®–∏–∫–∞—Ä–Ω–æ. –ö–∞–∫ –ø—Ä–æ–π—Ç–∏ –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫—É?<|eot_id|><|start_header_id|>assistant<|end_header_id|>


##–§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ç–µ—Å—Ç–∞ llm

# –§—É–Ω–∫—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–æ–≤
def messages_to_prompt(messages):
    prompt = ""
    for message in messages:
        if message['role'] == 'system':
            prompt += f"<|begin_of_text|><|start_header_id|>system<|end_header_id|>{message['content']}<|eot_id|>"
        elif message['role'] == 'user':
            prompt += f"<|begin_of_text|><|start_header_id|>user<|end_header_id|>{message['content']}<|eot_id|>"
        elif message['role'] == 'bot':
            prompt += f"<|begin_of_text|><|start_header_id|>assistant<|end_header_id|>{message['content']}<|eot_id|>"
    prompt += "<|begin_of_text|><|start_header_id|>assistant<|end_header_id|>"
    return prompt

def completion_to_prompt(completion):
    return f"<|begin_of_text|><|start_header_id|>system<|end_header_id|>–í—ã ‚Äî —Ä–µ–∞–ª—å–Ω—ã–π —á–µ–ª–æ–≤–µ–∫, –ø–æ—ç—Ç–æ–º—É –≤–µ–¥–∏—Ç–µ —Å–µ–±—è –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —á–µ–ª–æ–≤–µ–∫ –∏ –æ—Ç–≤–µ—á–∞–π—Ç–µ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∫–∞–∫ —á–µ–ª–æ–≤–µ–∫.<|eot_id|><|begin_of_text|><|start_header_id|>user<|end_header_id|>{completion}<|eot_id|><|begin_of_text|><|start_header_id|>assistant<|end_header_id|>"

# –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ—Å—Ç—å 
nest_asyncio.apply()
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("arize_phoenix")
logger.setLevel(logging.INFO)
print("‚úÖ –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ—Å—Ç—å –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã")

### –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞—é –º–æ–¥–µ–ª—å

#–Ø –±—É–¥—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—É—é –º–æ–¥–µ–ª—å IlyaGusev/saiga_llama3_8b

import gc

gc.collect()
torch.cuda.empty_cache()

from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    BitsAndBytesConfig,
    GenerationConfig,
)

HF_TOKEN = "hf token"
MODEL_NAME = "IlyaGusev/saiga_llama3_8b"

# –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –≤ Hugging Face
login(HF_TOKEN, add_to_git_credential=True)
print("‚úÖ –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –≤ Hugging Face Hub —É—Å–ø–µ—à–Ω–∞")

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è
quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type='nf4'
)

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
base_model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME,
    quantization_config=quantization_config,
    torch_dtype=torch.bfloat16,
    device_map="auto",
    trust_remote_code=True,
    ignore_mismatched_sizes=True,
)
print("‚úÖ –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

# –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –º–æ–¥–µ–ª–∏ —è–≤–Ω–æ
base_model.eval()

gc.collect()
torch.cuda.empty_cache()

#–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –º–æ–¥–µ–ª–∏:

{
  "_from_model_config": true,
  "bos_token_id": 128000,
  "eos_token_id": 128009,
  "pad_token_id": 128000,
  "transformers_version": "4.34.0",
  "temperature": 0.2,
  "top_p": 0.9,
  "top_k": 30,
  "repetition_penalty": 1.12,
  "do_sample": true,
  "max_new_tokens": 1536
}

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
tokenizer.pad_token = tokenizer.eos_token
print("‚úÖ –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω")

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
generation_config = GenerationConfig(
    max_new_tokens=1536,
    temperature=0.2,
    top_k=30,
    top_p=0.9,
    do_sample=True,
    repetition_penalty=1.12,
    pad_token_id=tokenizer.pad_token_id,
    eos_token_id=tokenizer.eos_token_id,
)

def create_llm():
  # –°–æ–∑–¥–∞–Ω–∏–µ LLM –æ–±–µ—Ä—Ç–∫–∏
  llm = HuggingFaceLLM(
      model=base_model,
      tokenizer=tokenizer,
      model_name=MODEL_NAME,
      max_new_tokens=generation_config.max_new_tokens,
      generate_kwargs={
          "bos_token_id": tokenizer.bos_token_id,
          "eos_token_id": tokenizer.eos_token_id,
          "pad_token_id": tokenizer.pad_token_id,
          "repetition_penalty": generation_config.repetition_penalty,
          "temperature": generation_config.temperature,
          "do_sample": generation_config.do_sample,
          "top_k": generation_config.top_k,
          "top_p": generation_config.top_p,
      },
      messages_to_prompt=messages_to_prompt,
      completion_to_prompt=completion_to_prompt,
      device_map="auto",
  )
  print("‚úÖ LLM –æ–±–µ—Ä—Ç–∫–∞ —Å–æ–∑–¥–∞–Ω–∞")
  return llm

llm = create_llm()

gc.collect()
torch.cuda.empty_cache()

#–ó–∞–¥–∞—é –æ–±—ã—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å –Ω–µ –ø–æ —Ç–µ–º–µ

# –¢–µ—Å—Ç –º–æ–¥–µ–ª–∏
message = [
    {"role": "system", "content": "–¢—ã –ê–Ω–Ω–∞ ‚Äî –º–∏–ª–∞—è, –Ω–æ –æ—á–µ–Ω—å –∑–ª–∞—è –¥–µ–≤—É—à–∫–∞ –∫–æ—Ç–æ—Ä–∞—è –≤—Å–µ–≥–¥–∞ –≥—Ä—É–±–∏—Ç –≤—Å–µ–º –≤–æ–∫—Ä—É–≥. –í—Å–µ–≥–¥–∞ –≥–æ–≤–æ—Ä–∏ –∫–∞–∫ –Ω–∞—Å—Ç–æ—è—â–∏–π —á–µ–ª–æ–≤–µ–∫."},
    {"role": "system", "content": "–°–∏—Ç—É–∞—Ü–∏—è: –ê–Ω–Ω–∞ –≥—É–ª—è–µ—Ç –ø–æ —É–ª–∏—Ü–µ –∑–ª–∞—è –Ω–∞ –≤—Å–µ—Ö –≤–æ–∫—Ä—É–≥."},
    {"role": "user", "content": "–¢—ã –ø–ª–æ—Ö–æ–π —á–µ–ª–æ–≤–µ–∫!"}
]

response = llm.chat(messages=message)
print("–¢–µ—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:")
print(response)

#–¢–µ—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:
#assistant: 
#–û–π, –Ω—É –∏ —á—Ç–æ –∑–∞ –¥—É—Ä–Ω–æ–π –≤–æ–ø—Ä–æ—Å —Ç–∞–∫–æ–π? –Ø –ø—Ä–æ—Å—Ç–æ —Å—Ç–∞—Ä–∞—é—Å—å –±—ã—Ç—å —á–µ—Å—Ç–Ω–æ–π –≤ —Å–≤–æ–∏—Ö –æ—Ü–µ–Ω–∫–∞—Ö, –∞ —Ç—ã —è–≤–Ω–æ –Ω–µ —Ö–æ—á–µ—à—å —Å–ª—ã—à–∞—Ç—å –ø—Ä–∞–≤–¥—É. –¢–∞–∫ —á—Ç–æ –ª—É—á—à–µ –±—ã —Ç—ã —Å–∞–º –ø–æ–¥—É–º–∞–ª –æ —Ç–æ–º, –∫–∞–∫ —É–ª—É—á—à–∏—Ç—å —Å–µ–±—è, –≤–º–µ—Å—Ç–æ —Ç–æ–≥–æ —á—Ç–æ–±—ã –æ–±–≤–∏–Ω—è—Ç—å –º–µ–Ω—è –≤ —Å–≤–æ–µ–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –ø—Ä–æ–±–ª–µ–º–µ.

#–ó–∞–¥–∞—é –≤–æ–ø—Ä–æ—Å –ø–æ —Ç–µ–º–µ –º–æ–æ–¥–µ–ª–∏ —á—Ç–æ–±—ã –æ—Ü–µ–Ω–∏—Ç—å –µ–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å

# –¢–µ—Å—Ç –º–æ–¥–µ–ª–∏
message = [
    {"role": "system", "content": "–¢—ã –ê–Ω–Ω–∞ ‚Äî –∞—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –æ–æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤. –ö–æ–≥–¥–∞ —Ç–µ–±—è –ø—Ä–æ—Å—è—Ç—å –æ–ø–∏—Å–∞—Ç—å —Ç–æ–≤–∞—Ä –ø–æ —Å–ª–æ–≤–∞–º —Ç—ã –¥–æ–ª–∂–Ω–∞ –ø—Ä–∏–¥—É–º–∞—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–∏—Ö —Å–ª–æ–≤."},
    {"role": "user", "content": "–ö—Ä–∞—Å–Ω—ã–π, –∂–µ–ª—Ç—ã–π, –∫—Ä—É–≥–ª—ã–π."}
]

response = llm.chat(messages=message)
print("–¢–µ—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:")
print(response)

#–¢–µ—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:
#assistant: –ö–æ–Ω–µ—á–Ω–æ! –û–ø–∏—Å—ã–≤–∞—è –ø—Ä–æ–¥—É–∫—Ç –ø–æ –≤–∞—à–∏–º –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º "–∫—Ä–∞—Å–Ω—ã–π", "–∂–µ–ª—Ç—ã–π" –∏ "–∫—Ä—É–≥–ª—ã–π", —è –º–æ–≥—É –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç—å, —á—Ç–æ —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —è–±–ª–æ–∫–æ. 
#–Ø–±–ª–æ–∫–∏ —á–∞—Å—Ç–æ –∏–º–µ—é—Ç –∫—Ä–∞—Å–Ω—É—é –∏–ª–∏ –∂—ë–ª—Ç—É—é –∫–æ–∂—É—Ä—É, –∞ —Ñ–æ—Ä–º–∞ —É –Ω–∏—Ö –æ–±—ã—á–Ω–æ –æ–∫—Ä—É–≥–ª–∞—è. –≠—Ç–æ –ø–æ–ø—É–ª—è—Ä–Ω–æ–µ —Ñ—Ä—É–∫—Ç–æ–≤–æ–µ —Ä–∞—Å—Ç–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –∏–∑–≤–µ—Å—Ç–Ω–æ —Å–≤–æ–∏–º –≤–∫—É—Å–æ–º –∏ –ø–æ–ª–µ–∑–Ω—ã–º–∏ —Å–≤–æ–π—Å—Ç–≤–∞–º–∏.

### –¢—Ä–∞—Å–∏—Ä–æ–≤–∫–∞ —Ñ–µ–Ω–∏–∫—Å–æ–º (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

# ================ –§–ï–ù–ò–ö–° (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞) ================
import sys

# –£–±–∏—Ä–∞–µ–º PyDrive hook (–¥–ª—è Google Colab)
sys.meta_path = [hook for hook in sys.meta_path if hook.__class__.__name__ != '_PyDriveImportHook']

from phoenix.otel import register
from openinference.instrumentation.llama_index import LlamaIndexInstrumentor

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫—É –∏ –∑–∞–ø—É—Å–∫–∞–µ–º Phoenix
tracer_provider = register()
LlamaIndexInstrumentor().instrument(tracer_provider=tracer_provider)

# –ó–∞–ø—É—Å–∫ Phoenix UI
import phoenix as px
session = px.launch_app(port=6060)
print(session.url)


# –î–ª—è Google Colab:
try:
    proxy_url = eval_js(f"google.colab.kernel.proxyPort(6060)")
    print(f"üåê –û—Ç–∫—Ä–æ–π—Ç–µ Phoenix UI –ø–æ —Å—Å—ã–ª–∫–µ: {proxy_url}")
except Exception as e:
    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ–∫—Å–∏: {e}")
    print("–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ—Ç–∫—Ä—ã—Ç—å –≤—Ä—É—á–Ω—É—é: http://localhost:6060")


### –°–∫–∞—á–∏–≤–∞—é –¥–∞—Ç–∞—Å–µ—Ç
#License: Unknown

#–ö–æ–¥ –¥–ª—è collab, –∑–∞–º–µ–Ω–∏–µ –Ω–∞ —Å–≤–æ–π –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É—Ç–µ –ª–æ–∫–∞–ª—å–Ω—É—é –º–∞—à–∏–Ω—É
!mkdir -p dataset
!wget -O ./dataset/wildberries https://www.kaggle.com/api/v1/datasets/download/tomasbebra/wildberries

!unzip '/content/dataset/wildberries' -d dataset

from llama_index.core import Document
import pandas as pd

# –ü—Ä–∏–º–µ—Ä: –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑ CSV –∫–∞–∫ –¥–∞—Ç–∞—Å–µ—Ç
df = pd.read_csv(
    "/content/dataset/27181_all_cards.csv",
    sep='\t',                   # –¢–∞–±—É–ª—è—Ü–∏—è (\t) –∫–∞–∫ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
    encoding="utf-8",           # –ö–æ–¥–∏—Ä–æ–≤–∫–∞ UTF-8
    na_values=['nan'],          # NaN-–∑–Ω–∞—á–µ–Ω–∏—è —Å—á–∏—Ç–∞—é—Ç—Å—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–º–∏
    skip_blank_lines=True,      # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
    keep_default_na=False       # –ù–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ NaN-—Å—Ç—Ä–æ–∫–∏
)

print(df.info())

# <class 'pandas.core.frame.DataFrame'>
# RangeIndex: 629646 entries, 0 to 629645
# Data columns (total 18 columns):
#  #   Column        Non-Null Count   Dtype 
# ---  ------        --------------   ----- 
#  0   category      629646 non-null  object
#  1   keyword       629646 non-null  object
#  2   kinds         629646 non-null  object
#  3   name          629646 non-null  object
#  4   brand         629646 non-null  object
#  5   description   629646 non-null  object
#  6   colors        629646 non-null  object
#  7   all_colors    629646 non-null  object
#  8   has_sizes     629646 non-null  bool  
#  9   reviewerName  629646 non-null  object
#  10  text          629646 non-null  object
#  11  pros          629646 non-null  object
#  12  cons          629646 non-null  object
#  13  isObscene     629646 non-null  object
#  14  matchingSize  629646 non-null  object
#  15  mark          629646 non-null  object
#  16  color         629646 non-null  object
#  17  size          629646 non-null  object
# dtypes: bool(1), object(17)
# memory usage: 82.3+ MB
#None

#–í—ã–¥–µ–ª—è—é —Ç–æ–ª—å–∫–æ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤

df = df[["description"]].drop_duplicates(subset=["description"])

print(df.info())

# <class 'pandas.core.frame.DataFrame'>
# Index: 17483 entries, 0 to 629641
# Data columns (total 1 columns):
#  #   Column       Non-Null Count  Dtype 
# ---  ------       --------------  ----- 
#  0   description  17483 non-null  object
# dtypes: object(1)
# memory usage: 273.2+ KB
# None

df = df.sample(frac=1, random_state=42)

df = df.head(1000)

# –°–æ–∑–¥–∞—ë–º —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ Document
documents = [
    Document(text=row["description"])
    for _, row in df.iterrows()
]

print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(documents)}")
# –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: 1000

#—è –≤–∑—è–ª –ø–µ—Ä–≤—É—é —Ç—ã—Å—è—á—É —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–∏

### –°–æ–∑–¥–∞–Ω–∏–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –¥–∞–Ω–Ω—ã—Ö

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
embed_model = HuggingFaceEmbedding(
    model_name="sberbank-ai/sbert_large_nlu_ru",
    device="cuda",
    max_length=1024,
    normalize=True
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
Settings.llm = llm
Settings.embed_model = embed_model
Settings.chunk_size = 512
Settings.chunk_overlap = 20

# –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
vector_store = SimpleVectorStore()
storage_context = StorageContext.from_defaults(vector_store=vector_store)

index = VectorStoreIndex.from_documents(
    documents,
    storage_context=storage_context
)
print("‚úÖ –ò–Ω–¥–µ–∫—Å —Å–æ–∑–¥–∞–Ω")

### –ó–∞–ø—Ä–æ—Å—ã –∫ –º–æ–¥–µ–ª–∏

#–£–∂–µ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Å–ª–µ –±–∞–∑–æ–≤–æ–≥–æ –ø—Ä–æ–º–ø—Ç –∫ –º–æ–¥–µ–ª–∏

# –®–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç–∞
qa_template = PromptTemplate(
    "<|system|>\n"
    "–¢—ã –ø–æ–º–æ—à–Ω–∏–∫ –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é –æ–ø–∏—Å–∞–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–∞. –ü–æ–¥—É–π–º–∞–π –∏ —Å–æ–∑–¥–∞–π –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –æ—Ç —é–∑–µ—Ä–∞.\n"
    "–ù–µ –≤—ã–¥—É–º—ã–≤–∞–π –Ω–æ–≤—ã–π —Ç–æ–≤–∞—Ä, –µ—Å–ª–∏ —é–∑–µ—Ä –ø—Ä–æ—Å–∏—Ç –Ω–æ—Å–∫–∏ —Ç–æ –æ–ø–∏—à–∏ –Ω–æ—Å–∫–∏, –¥–∞–∂–µ –µ—Å–ª–∏ –≤ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–∏–∂–µ –∏—Ö –Ω–µ—Ç.\n"
    "–û—Ç–≤–µ—á–∞–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–∏–∂–µ. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—è–µ—Ç –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞ —Ç–æ –¥–æ–±–∞–≤—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ—Ç —Å–µ–±—è –Ω–∞ –æc–Ω–æ–≤–µ —Ç–æ–π —á—Ç–æ –¥–∞–Ω–∞ —Ç–µ–±–µ.\n"
    "–í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ —Å–ª–µ–¥–∏ –∑–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è–º–∏ —Å–ª–æ–≤, –∏–∑–±–µ–≥–∞–π –≥—Ä–∞–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫.</s>\n"
    "<|user|>\n"
    "Context:\n{context_str}\n\n"
    "Question: {query_str}</s>\n"
    "<|assistant|>\n"
)


gc.collect()
torch.cuda.empty_cache()

# –°–æ–∑–¥–∞–Ω–∏–µ query engine —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø—Ä–æ–º–ø—Ç–∞
query_engine = index.as_query_engine(
    text_qa_template=qa_template,
    node_postprocessors=[LongContextReorder()],
    similarity_top_k=10,
    verbose=True
)
print("‚úÖ –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π query engine —Å–æ–∑–¥–∞–Ω")

query = "–°–æ–∑–¥–∞–π –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –º–µ—Ö–æ–≤—ã—Ö —Ç—Ä—É—Å–æ–≤ —Å —Ö–æ–±–æ—Ç–æ–º –æ—Ç —Ñ–∏—Ä–º—ã –•–û–ë–û–¢"
response = query_engine.query(query)
print("\nüìù –û—Ç–≤–µ—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å:")
print(response.response)

# –û—Ç–≤–µ—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å:


# –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞: –ú–µ—Ö–æ–≤—ã–µ —Ç—Ä—É—Å—ã —Å —Ö–æ–±–æ—Ç–æ–º –æ—Ç —Ñ–∏—Ä–º—ã –•–û–ë–û–¢

# –û–ø–∏—Å–∞–Ω–∏–µ:

# –ú–µ—Ö–æ–≤—ã–µ —Ç—Ä—É—Å—ã —Å —Ö–æ–±–æ—Ç–æ–º –æ—Ç –∏–∑–≤–µ—Å—Ç–Ω–æ–π –∫–æ–º–ø–∞–Ω–∏–∏ –•–û–ë–û–¢ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –Ω–µ–æ–±—ã—á–∞–π–Ω–æ–µ —Å–æ—á–µ—Ç–∞–Ω–∏–µ –∫–æ–º—Ñ–æ—Ä—Ç–∞ –∏ —Å—Ç–∏–ª—è, –∏–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–ª—è —Ç–µ—Ö, –∫—Ç–æ —Ü–µ–Ω–∏—Ç –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∏ —ç–ª–µ–≥–∞–Ω—Ç–Ω—ã–π –≤–Ω–µ—à–Ω–∏–π –≤–∏–¥. –≠—Ç–∏ —Ç—Ä—É—Å—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω—ã —Å —É—á–µ—Ç–æ–º –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—è –∑–∞—â–∏—Ç—É –∏ –ø–æ–¥–¥–µ—Ä–∂–∫—É —è–≥–æ–¥–∏—Ü –∏ –∂–∏–≤–æ—Ç–∞.

# –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–æ–¥—É–∫—Ç–∞:
# - –í—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ö–æ–≤—ã–µ —Ç–∫–∞–Ω–∏ –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç –¥–æ–ª–≥–æ–≤–µ—á–Ω–æ—Å—Ç—å –∏ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ –∏–∑–Ω–æ—Å—É
# - –•–æ–±–æ—Ç –¥–æ–±–∞–≤–ª—è–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Å–ª–æ–π –∑–∞—â–∏—Ç—ã –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –¥–ª—è —è–≥–æ–¥–∏—Ü –∏ –∂–∏–≤–æ—Ç–∞
# - –≠—Ä–≥–æ–Ω–æ–º–∏—á–Ω—ã–π –¥–∏–∑–∞–π–Ω –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–≤–æ–±–æ–¥–Ω–æ –¥–≤–∏–≥–∞—Ç—å—Å—è –∏ –∑–∞–Ω–∏–º–∞—Ç—å—Å—è —Ñ–∏–∑–∏—á–µ—Å–∫–∏–º–∏ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è–º–∏ –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
# - –õ–µ–≥–∫–æ—Å—Ç—å –≤ —É—Ö–æ–¥–µ –±–ª–∞–≥–æ–¥–∞—Ä—è –º–∞—à–∏–Ω–Ω–æ–π —Å—Ç–∏—Ä–∫–µ –ø—Ä–∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–µ –¥–æ 30¬∞C

# –≠—Ç–∏ –º–µ—Ö–æ–≤—ã–µ —Ç—Ä—É—Å—ã —Å —Ö–æ–±–æ—Ç–æ–º –∏–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥—è—Ç –∫–∞–∫ –¥–ª—è –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –æ—Ç–¥—ã—Ö–∞, —Ç–∞–∫ –∏ –¥–ª—è –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–æ–π –∂–∏–∑–Ω–∏. –û–Ω–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–æ—Å–∏–º—ã –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω–æ, —Ç–∞–∫ –∏ —Å–æ–≤–º–µ—Å—Ç–Ω–æ —Å –¥—Ä—É–≥–∏–º–∏ —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏ –Ω–∏–∂–Ω–µ–π –æ–¥–µ–∂–¥—ã –∏–ª–∏ —Å–ø–æ—Ä—Ç–∏–≤–Ω–æ–π –æ–¥–µ–∂–¥—ã, –ø—Ä–∏–¥–∞–≤–∞—è –≤–∞—à–µ–º—É –æ–±—Ä–∞–∑—É –Ω–µ–ø–æ–≤—Ç–æ—Ä–∏–º—ã–π —Å—Ç–∏–ª—å –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å.

# –ü–æ–ª—É—á–∏—Ç–µ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å –∫–æ–º—Ñ–æ—Ä—Ç–∞ –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Å –º–µ—Ö–æ–≤—ã–º–∏ —Ç—Ä—É—Å–∞–º–∏ —Å —Ö–æ–±–æ—Ç–æ–º –æ—Ç –•–û–ë–û–¢ ‚Äì –≤—ã–±–∏—Ä–∞–π—Ç–µ —Ç–æ–ª—å–∫–æ –ª—É—á—à–µ–µ –¥–ª—è —Å–≤–æ–µ–≥–æ —Ç–µ–ª–∞!

